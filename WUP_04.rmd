---
title: "WUP_04"
author: "Kiara Butler !"
date: "fall 2023"
output:
  html_document:
    df_print: paged
---

```{r include=FALSE,echo=FALSE}
require(knitr)
require(tidyverse)
require(tigerstats)
mydata<- read.csv(file="GSScsv.csv")
```


```{r eval=FALSE}
mydata <- mydata %>%
mutate(across(where(is.character), as.factor))
```
# Introduction

<!--In this section you explain what you are trying to show.  Where did the data come from?  What is the research or other question you are trying to answer?!-->

The data is in the file GSScsv.csv and came from the 2018 General Social Survey.  The question to answer is to resolve this hypothesis.  
$H_0$ There is no difference between the average score on the WORDSUM test and level of schooling DEGREE  
$H_a$ There is a significant difference in average score on the WORDSUM test between at least two levels of DEGREE  

# Methods

<!--Mention that you intend to use chatGPT to the greatest extent possible. Give credit to chatGPT when you use it to create code in your report. Decide on your methods:  use "variable analysis" or other appropriate descriptors.  Make sure to choose at least one graphical method and at least one numerical method.!-->

Using Chatgpt and CandP helper files close numerical data categorical data in the GSS data set. We will compare WORDSUM and how it effected by education level.
# Results

<!--Divide this section into two sub-sections:  One for your descriptive  results and one for your inferential results.!-->

## Descriptive Results

### Graphical Descriptive Results

<!--Graphical results here.  Make sure to show your code.  Provide appropriate labels for axes, giving units if possible, and provide a good title for the graph, too.  Use the graphical results to describe the patterns if any that exist in the data as focused toward the research question!-->



```{r include=TRUE,echo=FALSE}
ggplot(data = mydata, aes(x = DEGREE, y = WORDSUM) ) +
geom_boxplot ( notch=FALSE , outlier.colour = "red" , outlier.size = 2 , fill = "darkgray" ) +
stat_boxplot ( geom = 'errorbar' ) +
labs ( x = "DEGREE" , y = "WORDSUM SCORE" , title = "WORDSUM EXAPLINED BY DEGREE" ) +
theme ( plot.title = element_text (hjust = 0.5, size = 16) )
```


### Numerical Descriptive Results


<!--Numerical results go here. Use the numerical results to describe the patterns if any that exist in the data as focused toward the research question!-->

```{r include=TRUE,echo=FALSE}
favstats(WORDSUM ~ DEGREE , data = mydata )
```

the mean and median pf the lt high school and the high school categories are lower than the means and medians of the university-level data points.

## Inferential Results

<!--State hypothesis clearly.  Make sure your discussion of the inferential test covers all the aspects that the test output produces, such as test statistic, p-value etc.  Make a decision about the null hypothesis, explain the assumptions on which the selected test/procedure was based, and why the chosen procedure satisfys the assumptions and is appropriate to answer the research question!-->



```{r include=TRUE,echo=FALSE}
model1 <- aov(WORDSUM ~ DEGREE , data = mydata )
summary.aov(model1)
```


```{r include=TRUE,echo=FALSE}
par(mar = c(3, 8.7, 2, 2))
plot(TukeyHSD(model1, conf.level = 0.99),las=2)
```

Our analysis provides strong evidence tht education levels have meanigful impact on WORDSUM test scores. The ANOVA test, p - value below 0.05, highlights a significant difference in scores among education levels. Turkeys HSD test further confirms that individuals with Assiosiate, Bacholor, or Graduate Degrees tend to achieve higher WORDSUM scores compared to those with only a high school education or less.

#Disscusion and Conculsion 

<!--Discussion and conclusion here. If you found a relationship be sure to consider whether the relationship occurs because one of the variavbles causes the other, or whether they perhasps are related for some other reason. Watch the chapter 6 videos from the GeorgeTown videos collection.!-->cussion and Conclusion

In this write up we were given a mydata with the categories we were asked to analyze. for our x value it was a WORDSUM whicth

